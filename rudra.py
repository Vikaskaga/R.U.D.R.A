# -*- coding: utf-8 -*-
"""RUDRA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_w2stQVhIiGSHS1F30dxRBVTt5FO0gvO
"""

pip install feedparser newspaper3k transformers sentence-transformers torch jinja2

pip install beautifulsoup4 lxml

pip install lxml[html_clean]

import feedparser
import newspaper
import os
import datetime
from transformers import pipeline
from sentence_transformers import SentenceTransformer, util
from jinja2 import Template

# Define user personas
personas = [
    {"name": "Alex Parker", "interests": ["AI", "cybersecurity", "blockchain", "startups", "programming"], "sources": ["https://techcrunch.com/feed/", "https://www.wired.com/feed/rss", "https://www.technologyreview.com/feed/"]},
    {"name": "Priya Sharma", "interests": ["global markets", "startups", "fintech", "cryptocurrency", "economics"], "sources": ["https://www.bloomberg.com/feed", "https://www.ft.com/?format=rss", "https://www.coindesk.com/arc/outboundfeeds/rss/"]},
    {"name": "Marco Rossi", "interests": ["football", "F1", "NBA", "Olympic sports", "esports"], "sources": ["https://www.espn.com/espn/rss/news", "http://feeds.bbci.co.uk/sport/rss.xml", "https://www.skysports.com/rss/12040"]},
    {"name": "Lisa Thompson", "interests": ["movies", "celebrity news", "TV shows", "music", "books"], "sources": ["https://variety.com/feed/", "https://www.hollywoodreporter.com/t/feed/", "https://www.billboard.com/feed/"]},
    {"name": "David Martinez", "interests": ["space exploration", "AI", "biotech", "physics", "renewable energy"], "sources": ["https://www.nasa.gov/rss/dyn/breaking_news.rss", "https://www.sciencedaily.com/rss/top/science.xml", "https://arstechnica.com/science/feed/"]}
]

# Summarizer & Embedding models
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
embedder = SentenceTransformer('all-MiniLM-L6-v2')

# Template for markdown
newsletter_template = """# {{name}}'s Personalized Newsletter
**Date:** {{date}}

## Highlights:
{% for article in highlights %}
- [{{ article['title'] }}]({{ article['link'] }}) - *{{ article['summary'] }}*
{% endfor %}

{% for topic, articles in categorized.items() %}
## {{topic}}
{% for article in articles %}
- [{{ article['title'] }}]({{ article['link'] }}) - *{{ article['summary'] }}*
{% endfor %}
{% endfor %}
"""

def fetch_articles(sources):
    articles = []
    for url in sources:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            try:
                art = newspaper.Article(entry.link)
                art.download()
                art.parse()
                summary = summarizer(art.text[:1024], max_length=60, min_length=10, do_sample=False)[0]['summary_text']
                articles.append({"title": entry.title, "link": entry.link, "text": art.text, "summary": summary})
            except Exception:
                continue
    return articles

def select_relevant_articles(articles, interests):
    scores = []
    interest_embeddings = embedder.encode(interests, convert_to_tensor=True)
    for article in articles:
        art_embedding = embedder.encode(article['summary'], convert_to_tensor=True)
        score = util.cos_sim(interest_embeddings, art_embedding).max().item()
        scores.append((article, score))
    scores.sort(key=lambda x: x[1], reverse=True)
    top_articles = [item[0] for item in scores[:10]]
    categorized = {}
    for art in top_articles:
        for interest in interests:
            if interest.lower() in art['summary'].lower():
                categorized.setdefault(interest.title(), []).append(art)
                break
        else:
            categorized.setdefault("Other", []).append(art)
    return categorized, top_articles[:3]

def generate_newsletter(persona):
    articles = fetch_articles(persona['sources'])
    categorized, highlights = select_relevant_articles(articles, persona['interests'])
    template = Template(newsletter_template)
    output = template.render(name=persona['name'], date=str(datetime.date.today()), highlights=highlights, categorized=categorized)
    file_name = persona['name'].replace(" ", "_") + "_Newsletter.md"
    with open(file_name, "w", encoding='utf-8') as f:
        f.write(output)

# Run for all personas
for persona in personas:
    print(f"Generating newsletter for {persona['name']}...")
    generate_newsletter(persona)
print("All newsletters generated!")

!pip install markdown2 pdfkit

# Colab-Ready Script: Convert Markdown Newsletters to PDF

import markdown2
import pdfkit
import os

# Install wkhtmltopdf inside Colab
!apt-get install -y wkhtmltopdf

# Configure PDFKit to use Colab's wkhtmltopdf binary
config = pdfkit.configuration(wkhtmltopdf='/usr/bin/wkhtmltopdf')

# List of personas for file processing
personas_names = [
    "Alex_Parker",
    "Priya_Sharma",
    "Marco_Rossi",
    "Lisa_Thompson",
    "David_Martinez"
]

# PDF conversion settings
pdf_options = {
    'page-size': 'A4',
    'encoding': "UTF-8",
    'margin-top': '0.75in',
    'margin-right': '0.75in',
    'margin-bottom': '0.75in',
    'margin-left': '0.75in'
}

# Convert each markdown file to a PDF
def convert_md_to_pdf(md_file, pdf_file):
    with open(md_file, 'r', encoding='utf-8') as f:
        md_content = f.read()
    html_content = markdown2.markdown(md_content)
    pdfkit.from_string(html_content, pdf_file, options=pdf_options, configuration=config)

# Create PDFs for all personas
for persona in personas_names:
    md_file = f"{persona}_Newsletter.md"
    pdf_file = f"{persona}_Newsletter.pdf"
    if os.path.exists(md_file):
        print(f"Converting {md_file} to PDF...")
        convert_md_to_pdf(md_file, pdf_file)
    else:
        print(f"Markdown file for {persona} not found.")

print("All PDFs generated and saved in the current directory!")

def calculate_relevance_score(articles, interests):
    interest_embeddings = embedder.encode(interests, convert_to_tensor=True)
    scores = []
    for article in articles:
        art_embedding = embedder.encode(article['summary'], convert_to_tensor=True)
        score = util.cos_sim(interest_embeddings, art_embedding).max().item()
        scores.append(score)
    avg_score = sum(scores) / len(scores) if scores else 0
    return avg_score

def generate_newsletter(persona):
    articles = fetch_articles(persona['sources'])
    categorized, selected_articles = select_relevant_articles(articles, persona['interests'])
    relevance_score = calculate_relevance_score(selected_articles, persona['interests'])
    print(f"Relevance Score for {persona['name']}: {relevance_score:.2f}")

    template = Template(newsletter_template)
    output = template.render(name=persona['name'], date=str(datetime.date.today()), highlights=selected_articles[:3], categorized=categorized)
    file_name = persona['name'].replace(" ", "_") + "_Newsletter.md"
    with open(file_name, "w", encoding='utf-8') as f:
        f.write(output)

# Run for all personas
for persona in personas:
    print(f"Generating newsletter for {persona['name']}...")
    generate_newsletter(persona)
print("All newsletters generated with relevance scores displayed!")



